{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisão com algumas funções importantes para a PI de RobComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformando Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar imagem em RGB\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Transformar imagem em HSV\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Transforma em GRAY\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando Máscaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_lower = np.array([0, 0, 0])\n",
    "hsv_upper = np.array([255, 255, 255])\n",
    "\n",
    "mask = cv2.inRange(img_hsv, hsv_lower, hsv_upper)\n",
    "\n",
    "# Juntando Máscaras\n",
    "mask_junta = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "# Se for necessário, podemos suavisar as bordas da imagem com a seguinte função:\n",
    "kernel=np.ones((4,4), np.uint8)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrando Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara = np.zeros_like(gray)\n",
    "mascara[gray > 20] = 255\n",
    "# Define como branco todos os pixels maiores que 20 na escala cinza\n",
    "\n",
    "filtro_vermelho1 = np.zeros_like(gray)\n",
    "filtro_vermelho1[bgr[:,:,2] > 200] = 255\n",
    "# Define como branco todos os pixels maiores que 200 dentro do intervalo do vermelho"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contornos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achar Contornos\n",
    "- `mask` é a imagem com a máscara binária\n",
    "- `cv2.RETR_CCOMP` indica que queremos organizar os contornos em componentes conexos e buracos dentro deles\n",
    "- `cv2.CHAIN_APPROX_NONE` indica que queremos armazenar todos os pontos do contorno\n",
    "- `contours` é uma lista de contornos, contendo os pontos a ele pertencententes (x, y)\n",
    "- `hierarchy` é uma lista indicando a organização dos contornos em termos dos componentes e de seus buracos\n",
    "\n",
    "A função retorna três valores: os contornos propriamente ditos, a hierarquia dos contornos e o método de aproximação de contornos utilizado.\n",
    "\n",
    "- Contornos: é uma lista Python de todos os contornos encontrados na imagem. Cada contorno é representado por uma matriz NumPy de pontos (x,y) que o formam.\n",
    "- Hierarquia: é uma matriz NumPy que define a relação de cada contorno com os outros contornos encontrados. Ela pode ser usada para identificar contornos internos ou externos, por exemplo.\n",
    "- Método de aproximação de contornos: é um parâmetro opcional que define o método de aproximação de contornos utilizado. O valor padrão é cv2.CHAIN_APPROX_SIMPLE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É possível encontrar componente conexos em imagens tons de cinza através da função cv2.findContours(). \n",
    "# Ela considera pixels de valor maior do que 0 como pixels de interesse\n",
    "contornos, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP/cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista das coordenadas x e y dos contornos\n",
    "x_list = contornos[0][:,:,0]\n",
    "y_list = contornos[0][:,:,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achar os 4 maiores contornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contornos = sorted(contornos, key=cv2.contourArea)[-4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printar Contornos\n",
    "- `imagem` é a imagem colorida ou tons de cinza a receber o contorno\n",
    "- `contours` é a lista de contornos obtida com `cv2.findContours()`\n",
    "- `indice` é o índice do contorno dentro da lista a ser desenhado; se indice < 0 desenha todos os contornos\n",
    "- `cor` é a cor do pixel a ser usada para desenhar o contorno   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar contornos na imagem\n",
    "cv2.drawContours(img, contornos, indice, cor)\n",
    "\n",
    "# Exemplo:\n",
    "cv2.drawContours(img, contornos, -1, [0, 0, 255], 3) # 3 representa a espessura do contorno"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Área, Centro de Massa e Texto na Tela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Área dos contornos:\n",
    "area = cv2.contourArea(contours[indice]) # Recebe apenas um contorno por vez\n",
    "\n",
    "# Retorna a área em pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centro de Massa\n",
    "def center_of_contour(contorno): # Recebe apenas um contorno por vez\n",
    "    \"\"\" Retorna uma tupla (cx, cy) que desenha o centro do contorno\"\"\"\n",
    "    M = cv2.moments(contorno)\n",
    "    # Usando a expressão do centróide definida em: https://en.wikipedia.org/wiki/Image_moment\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    return (int(cX), int(cY))\n",
    "    \n",
    "def crosshair(img, point, size, color):\n",
    "    \"\"\" Desenha um crosshair centrado no point.\n",
    "        point deve ser uma tupla (x,y)\n",
    "        color é uma tupla R,G,B uint8\n",
    "    \"\"\"\n",
    "    x,y = point\n",
    "    cv2.line(img,(x - size,y),(x + size,y),color,5)\n",
    "    cv2.line(img,(x,y - size),(x, y + size),color,5)\n",
    "    \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "def texto(img, a, p):\n",
    "    \"\"\"Escreve na img RGB dada a string a na posição definida pela tupla p\"\"\"\n",
    "    cv2.putText(img, str(a), p, cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo:\n",
    "# Vamos percorrer a lista de contornos e aplicar as funções de centro de massa definidas acima\n",
    "\n",
    "for c in contornos:\n",
    "    a = cv2.contourArea(c) # área\n",
    "    p = center_of_contour(c) # centro de massa\n",
    "    crosshair(img, p, 20, (128,128,0)) # desenha o crosshair\n",
    "    texto(img, np.round(a,2),p) # escreve a área"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bordas\n",
    "- `mask`: máscara com valores em preto e branco.\n",
    "- `threshold1`: O valor mínimo do limiar para a detecção de bordas. Qualquer borda com intensidade abaixo desse valor será descartada.\n",
    "- `threshold2`: O valor máximo do limiar para a detecção de bordas. Qualquer borda com intensidade acima desse valor será considerada uma borda verdadeira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bordas utilizando o Canny:\n",
    "bordas = cv2.Canny(mask, 100, 200) # vamos padronizar o uso de 100 e 200 como limiares mas é possível alterar\n",
    "\n",
    "# Retorna a imagem com as bordas em preto e fundo em branco"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linhas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `image`: A imagem de entrada, que pode ser uma matriz NumPy ou um objeto cv2.Mat.\n",
    "- `rho`: A resolução do parâmetro rho da transformada de Hough em pixels. Geralmente é 1.\n",
    "- `theta`: A resolução do parâmetro theta da transformada de Hough em radianos. Geralmente é np.pi/180, que é aproximadamente 1 grau.\n",
    "- `threshold`: O valor do limiar usado para a detecção de linhas. A função irá retornar apenas as linhas que têm um número de votos maior do que o valor de limiar.\n",
    "- `minLineLength`: O comprimento mínimo da linha a ser detectada. Qualquer linha com comprimento abaixo desse valor será descartada.\n",
    "- `maxLineGap`: A distância máxima permitida entre segmentos de linha para serem conectados em uma única linha. Qualquer lacuna entre segmentos de linha maior do que esse valor será considerada como duas linhas separadas.\n",
    "- A função retorna uma matriz NumPy que representa as linhas detectadas na imagem. Cada linha é representada por um vetor de quatro elementos [x1 (inicial), y1 (inicial), x2 (final), y2 (final)] que especifica as coordenadas dos dois pontos que definem a linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linhas = cv2.HoughLinesP(bordas, 10, np.pi/180.0, threshold=150, minLineLength=50, maxLineGap=70) # Apenas um exemplo, pode ser alterado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Círculos\n",
    "- `image`: Imagem de 8 bits onde as circunferências serão procuradas\n",
    "- `method`: método usado para encontrar os possíveis centros de cada circunferência. Aqui vamos usar `cv2.HOUGH_GRADIENT`.\n",
    "- `dp`: resolução usada na procura pelos centros das circunferências\n",
    "- `minDist`: menor distância permitida entre os centros das circunferências encontradas\n",
    "- `param1`: limiar empregado na detecção dos pontos de borda\n",
    "- `param2`: limiar de detecção da circunferência\n",
    "- `minRadius`: menor raio da circunferência a ser encontradas\n",
    "- `maxRadius`: maior raio da circunferência a ser encontradas\n",
    "- A função retorna uma matriz NumPy que representa os círculos detectados na imagem. Cada círculo é representado por um vetor de três elementos [x, y, r] que especifica as coordenadas do centro do círculo e seu raio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro vamos transformar a imagem em tons de cinza\n",
    "grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Vamos achar os círculos (valores arbitrários)\n",
    "circles = cv2.HoughCircles(grey,\n",
    "                          cv2.HOUGH_GRADIENT,\n",
    "                          dp=1,\n",
    "                          minDist=20,\n",
    "                          param1=50, \n",
    "                          param2=30,\n",
    "                          minRadius=17,\n",
    "                          maxRadius=50)\n",
    "circles = np.uint16(np.around(circles))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printar Círculos\n",
    "- `imagem`: a imagem na qual o círculo será desenhado.\n",
    "- `centro`: as coordenadas do centro do círculo na imagem, no formato (x, y).\n",
    "- `raio`: o raio do círculo a ser desenhado, em pixels.\n",
    "- `cor`: a cor do círculo, no formato (B, G, R) ou escala de cinza.\n",
    "- `espessura`: a espessura da linha que desenha o círculo. Se for negativo, o círculo será preenchido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.circle(imagem, centro, raio, cor, espessura)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes e Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apenas um exemplo, pode ser que mude de acordo com a questão\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "\t\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "\t\"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "\t\"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mobilenet():\n",
    "    \"\"\"Não mude ou renomeie esta função\n",
    "        Carrega o modelo e os parametros da MobileNet. \n",
    "        Retorna a rede carregada.\n",
    "    \"\"\"\n",
    "    # Load the model.\n",
    "    net = cv2.dnn.readNetFromCaffe('MobileNetSSD_deploy.prototxt.txt', 'MobileNetSSD_deploy.caffemodel') #Parâmetros depende do arquivo\n",
    "    return net"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Detect\n",
    "- Não tente entender por completo kkkkk\n",
    "- Recebe uma imagem/frame e a net carregada anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame, net):\n",
    "    image = frame.copy()\n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "\n",
    "    # pass the blob through the network and obtain the detections and\n",
    "    # predictions\n",
    "    print(\"[INFO] computing object detections...\")\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # loop over the detections\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the\n",
    "        # prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # filter out weak detections by ensuring the `confidence` is\n",
    "        # greater than the minimum confidence\n",
    "\n",
    "        # Pode-se mudar o nível de confiança, mas alterará a precisão do resultado final, faça testes e decida o\n",
    "        # melhor valor.\n",
    "        if confidence > 0.5: \n",
    "            # extract the index of the class label from the `detections`,\n",
    "            # then compute the (x, y)-coordinates of the bounding box for\n",
    "            # the object\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # display the prediction\n",
    "            label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "            print(\"[INFO] {}\".format(label))\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "                COLORS[idx], 2)\n",
    "            y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "            cv2.putText(frame, label, (startX, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "\n",
    "            results.append((CLASSES[idx], confidence*100, (startX, startY),(endX, endY) ))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chamando a função e printando resultados\n",
    "- Recebe um frame/imagem e a função load_mobilenet()\n",
    "- `res` Retorna: o nome do objeto detectado, a acurácia de ser esse objeto (%) e duas tuplas (x1, y1), (x2, y2). Essas tuplas representam coordendas da diagonal do retângulo. Ex: [('dog', 94.97159123420715, (183, 383), (336, 536))]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = detect(frame, load_mobilenet())\n",
    "infos = resultados[0] # Ex: ('dog', 94.97159123420715, (183, 383), (336, 536))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo\n",
    "for resultado in resultados:\n",
    "    x1 = resultado[2][0]\n",
    "    y1 = resultado[2][1]\n",
    "    x2 = resultado[3][0]\n",
    "    y2 = resultado[3][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Próximos Passos\n",
    "- Agora depende de cada problema, have fun =)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
